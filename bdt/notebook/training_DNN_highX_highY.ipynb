{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import uproot\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import roc_curve, auc, accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torch.optim import Adam\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# File paths\n",
    "signal_files_lowX_lowY = [\n",
    "    (\"../../outputfiles/hhbbgg_analyzerNMSSM-trees.root\", \"/NMSSM_X650_Y95/preselection\"),\n",
    "    (\"../../outputfiles/hhbbgg_analyzerNMSSM-trees.root\", \"/NMSSM_X650_Y100/preselection\"),\n",
    "    (\"../../outputfiles/hhbbgg_analyzerNMSSM-trees.root\", \"/NMSSM_X650_Y125/preselection\"),\n",
    "    (\"../../outputfiles/hhbbgg_analyzerNMSSM-trees.root\", \"/NMSSM_X650_Y95/preselection\"),\n",
    "    (\"../../outputfiles/hhbbgg_analyzerNMSSM-trees.root\", \"/NMSSM_X700_Y100/preselection\"),\n",
    "    (\"../../outputfiles/hhbbgg_analyzerNMSSM-trees.root\", \"/NMSSM_X700_Y125/preselection\"),\n",
    "#     (\"../../outputfiles/hhbbgg_analyzerNMSSM-trees.root\", \"/NMSSM_X700_Y80/preselection\"),\n",
    "#     (\"../../outputfiles/hhbbgg_analyzerNMSSM-trees.root\", \"/NMSSM_X700_Y90/preselection\"),\n",
    "#     (\"../../outputfiles/hhbbgg_analyzerNMSSM-trees.root\", \"/NMSSM_X550_Y80/preselection\"),\n",
    "#     (\"../../outputfiles/hhbbgg_analyzerNMSSM-trees.root\", \"/NMSSM_X550_Y90/preselection\"),\n",
    "# #     (\"../../outputfiles/hhbbgg_analyzerNMSSM-trees.root\", \"/NMSSM_X550_Y95/preselection\"),\n",
    "# #     (\"../../outputfiles/hhbbgg_analyzerNMSSM-trees.root\", \"/NMSSM_X550_Y100/preselection\"),\n",
    "]\n",
    "\n",
    "background_files = [\n",
    "    (\"../../outputfiles/hhbbgg_analyzerNMSSM-trees.root\", \"/GGJets/preselection\"),\n",
    "    (\"../../outputfiles/hhbbgg_analyzerNMSSM-trees.root\", \"/GJetPt20To40/preselection\"),\n",
    "    (\"../../outputfiles/hhbbgg_analyzerNMSSM-trees.root\", \"/GJetPt40/preselection\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Columns to be loaded\n",
    "keys = [\n",
    "     'dibjet_pt', 'diphoton_pt', 'bbgg_pt', 'bbgg_eta', 'bbgg_phi',\n",
    "    'lead_pho_phi', 'sublead_pho_eta', 'sublead_pho_phi', 'diphoton_eta', \n",
    "    'diphoton_phi', 'dibjet_eta', 'dibjet_phi', 'lead_bjet_pt', 'sublead_bjet_pt', \n",
    "    'lead_bjet_eta', 'lead_bjet_phi', 'sublead_bjet_eta', 'sublead_bjet_phi', \n",
    "    'sublead_bjet_PNetB', 'lead_bjet_PNetB', 'CosThetaStar_gg', 'CosThetaStar_jj', \n",
    "    'CosThetaStar_CS', 'DeltaR_jg_min',   'pholead_PtOverM', 'phosublead_PtOverM',\n",
    "    'weight_preselection',\n",
    "]\n",
    "# Variables removed :- 'bbgg_mass','FirstJet_PtOverM', 'SecondJet_PtOverM', 'diphoton_bbgg_mass', 'dibjet_bbgg_mass', 'lead_pho_eta',\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Signal Shape: (135416, 27)\n",
      "Total Background Shape: (98635, 27)\n"
     ]
    }
   ],
   "source": [
    "# Load DataFrames\n",
    "dfs = {}\n",
    "\n",
    "# Load signal files\n",
    "for file, key in signal_files_lowX_lowY:\n",
    "    try:\n",
    "        with uproot.open(file) as f:\n",
    "            dfs[key] = f[key].arrays(keys, library=\"pd\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading {file} with key {key}: {e}\")\n",
    "\n",
    "# Load background files\n",
    "for file, key in background_files:\n",
    "    try:\n",
    "        with uproot.open(file) as f:\n",
    "            dfs[key] = f[key].arrays(keys, library=\"pd\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading {file} with key {key}: {e}\")\n",
    "\n",
    "# Combine signal DataFrames\n",
    "signal_df = pd.concat([dfs[key] for key in dfs if 'NMSSM' in key], ignore_index=True)\n",
    "background_df = pd.concat([dfs[key] for key in dfs if 'GJet' in key or 'GGJets' in key], ignore_index=True)\n",
    "\n",
    "\n",
    "\n",
    "# signal_df = pd.concat([])\n",
    "# Print combined sample sizes\n",
    "print(f'Total Signal Shape: {signal_df.shape}')\n",
    "print(f'Total Background Shape: {background_df.shape}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if 'weight_preselection' exists in all DataFrames\n",
    "if 'weight_preselection' not in signal_df.columns or 'weight_preselection' not in background_df.columns:\n",
    "    print(\"Error: 'weight_preselection' column missing in one or more DataFrames.\")\n",
    "    exit()\n",
    "\n",
    "# Assign labels\n",
    "signal_df['label'] = 1\n",
    "background_df['label'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined DataFrame Shape: (234051, 28)\n"
     ]
    }
   ],
   "source": [
    "# Combine signal and background data\n",
    "combined_df = pd.concat([signal_df, background_df], ignore_index=True)\n",
    "print(f'Combined DataFrame Shape: {combined_df.shape}')\n",
    "\n",
    "# Define features and labels\n",
    "features = [\n",
    "    'bbgg_eta', 'bbgg_phi', 'lead_pho_phi', 'sublead_pho_eta', \n",
    "    'sublead_pho_phi', 'diphoton_eta', 'diphoton_phi', 'dibjet_eta', 'dibjet_phi', \n",
    "    'lead_bjet_pt', 'sublead_bjet_pt', 'lead_bjet_eta', 'lead_bjet_phi', 'sublead_bjet_eta', \n",
    "    'sublead_bjet_phi', 'sublead_bjet_PNetB', 'lead_bjet_PNetB', 'CosThetaStar_gg', \n",
    "    'CosThetaStar_jj', 'CosThetaStar_CS', 'DeltaR_jg_min', 'pholead_PtOverM', \n",
    "    'phosublead_PtOverM'\n",
    "]\n",
    "\n",
    "# variables removed:  'bbgg_mass',  'lead_pho_eta','FirstJet_PtOverM', 'SecondJet_PtOverM', 'diphoton_bbgg_mass', 'dibjet_bbgg_mass'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X = combined_df[features]\n",
    "y = combined_df['label']\n",
    "weights = combined_df['weight_preselection']\n",
    "\n",
    "# Impute missing values and scale the data\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "X_imputed = imputer.fit_transform(X)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X_imputed)\n",
    "\n",
    "# Split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Extract weights for train and test datasets\n",
    "X_train_weights = combined_df.loc[X_train.index, 'weight_preselection']\n",
    "X_test_weights = combined_df.loc[X_test.index, 'weight_preselection']\n",
    "\n",
    "# Impute and scale the features\n",
    "X_train_imputed = imputer.fit_transform(X_train)\n",
    "X_test_imputed = imputer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled = scaler.fit_transform(X_train_imputed)\n",
    "X_test_scaled = scaler.transform(X_test_imputed)\n",
    "\n",
    "# Convert data to torch tensors\n",
    "X_train_tensor = torch.tensor(X_train_scaled, dtype=torch.float32)\n",
    "X_test_tensor = torch.tensor(X_test_scaled, dtype=torch.float32)\n",
    "\n",
    "y_train_tensor = torch.tensor(y_train.values, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test.values, dtype=torch.float32)\n",
    "X_train_weights_tensor = torch.tensor(X_train_weights.values, dtype=torch.float32)\n",
    "X_test_weights_tensor = torch.tensor(X_test_weights.values, dtype=torch.float32)\n",
    "\n",
    "# Create TensorDataset and DataLoader\n",
    "train_data = TensorDataset(X_train_tensor, y_train_tensor, X_train_weights_tensor)\n",
    "test_data = TensorDataset(X_test_tensor, y_test_tensor, X_test_weights_tensor)\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_data, batch_size=32, shuffle=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the neural network model\n",
    "class SimpleDNN(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(SimpleDNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, 128)\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.fc3 = nn.Linear(64, 32)\n",
    "        self.fc4 = nn.Linear(32, 16)\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        self.output = nn.Linear(16, 1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.relu(self.fc3(x))\n",
    "        x = self.relu(self.fc4(x))\n",
    "        x = self.sigmoid(self.output(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU is available.\n",
      "Device name: Tesla T4\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Check if a GPU is available\n",
    "if torch.cuda.is_available():\n",
    "    print(\"GPU is available.\")\n",
    "    print(f\"Device name: {torch.cuda.get_device_name(0)}\")\n",
    "else:\n",
    "    print(\"GPU is not available.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50, Train Loss: 547.0172, Train Accuracy: 0.9684\n",
      "Epoch 1/50, Test Loss: 115.4527, Test Accuracy: 0.9731\n",
      "Epoch 2/50, Train Loss: 464.1392, Train Accuracy: 0.9731\n",
      "Epoch 2/50, Test Loss: 108.5855, Test Accuracy: 0.9743\n",
      "Epoch 3/50, Train Loss: 449.1566, Train Accuracy: 0.9739\n",
      "Epoch 3/50, Test Loss: 105.9409, Test Accuracy: 0.9749\n",
      "Epoch 4/50, Train Loss: 441.4878, Train Accuracy: 0.9743\n",
      "Epoch 4/50, Test Loss: 105.7621, Test Accuracy: 0.9747\n",
      "Epoch 5/50, Train Loss: 434.1921, Train Accuracy: 0.9747\n",
      "Epoch 5/50, Test Loss: 102.8685, Test Accuracy: 0.9757\n",
      "Epoch 6/50, Train Loss: 427.3802, Train Accuracy: 0.9750\n",
      "Epoch 6/50, Test Loss: 102.5508, Test Accuracy: 0.9758\n",
      "Epoch 7/50, Train Loss: 420.0851, Train Accuracy: 0.9751\n",
      "Epoch 7/50, Test Loss: 103.2663, Test Accuracy: 0.9757\n",
      "Epoch 8/50, Train Loss: 417.5747, Train Accuracy: 0.9755\n",
      "Epoch 8/50, Test Loss: 101.8781, Test Accuracy: 0.9759\n",
      "Epoch 9/50, Train Loss: 414.4325, Train Accuracy: 0.9757\n",
      "Epoch 9/50, Test Loss: 102.2561, Test Accuracy: 0.9756\n",
      "Epoch 10/50, Train Loss: 415.0375, Train Accuracy: 0.9756\n",
      "Epoch 10/50, Test Loss: 103.4987, Test Accuracy: 0.9758\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam\n",
    "\n",
    "# Initialize the model\n",
    "input_dim = X_train.shape[1]\n",
    "model = SimpleDNN(input_dim)  # No device assignment needed\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Function to calculate accuracy\n",
    "def calculate_accuracy(outputs, labels):\n",
    "    preds = (outputs > 0.5).float()  # Convert outputs to binary predictions\n",
    "    correct = (preds == labels).float().sum()  # Count correct predictions\n",
    "    accuracy = correct / labels.size(0)  # Compute accuracy\n",
    "    return accuracy\n",
    "\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "train_accuracies = []\n",
    "test_accuracies = []\n",
    "\n",
    "# Training loop\n",
    "epochs = 50\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    train_accuracy = 0.0\n",
    "    for X_batch, y_batch, weight_batch in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(X_batch).squeeze()\n",
    "        loss = criterion(outputs, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "        train_accuracy += calculate_accuracy(outputs, y_batch).item()\n",
    "\n",
    "    # Average training accuracy\n",
    "    train_accuracy /= len(train_loader)\n",
    "    train_losses.append(train_loss / len(train_loader))\n",
    "    train_accuracies.append(train_accuracy)\n",
    "\n",
    "\n",
    "    # Evaluate on test data\n",
    "    model.eval()\n",
    "    test_loss = 0.0\n",
    "    test_accuracy = 0.0\n",
    "    test_outputs = []\n",
    "    test_labels = []\n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch, weight_batch in test_loader:\n",
    "            outputs = model(X_batch).squeeze()\n",
    "            loss = criterion(outputs, y_batch)\n",
    "            test_loss += loss.item()\n",
    "            test_outputs.append(outputs.numpy())\n",
    "            test_labels.append(y_batch.numpy())\n",
    "    \n",
    "    # Combine lists into numpy arrays\n",
    "    test_outputs = np.concatenate(test_outputs)\n",
    "    test_labels = np.concatenate(test_labels)\n",
    "    \n",
    "    # Calculate test accuracy\n",
    "    test_accuracy = calculate_accuracy(torch.tensor(test_outputs), torch.tensor(test_labels)).item()\n",
    "\n",
    "    print(f'Epoch {epoch + 1}/{epochs}, Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.4f}')\n",
    "    print(f'Epoch {epoch + 1}/{epochs}, Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "# Move tensors to CPU before converting to NumPy arrays\n",
    "y_train_pred = model(X_train_tensor).cpu().detach().numpy()\n",
    "y_test_pred = model(X_test_tensor).cpu().detach().numpy()\n",
    "\n",
    "# Plot ROC curves and calculate AUC\n",
    "def plot_roc(y_true, y_pred, title):\n",
    "    fpr, tpr, _ = roc_curve(y_true, y_pred)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    plt.plot(fpr, tpr, label=f'AUC = {roc_auc:.2f}')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title(title)\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plot_roc(y_train, y_train_pred, 'ROC Curve (Train Data)')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plot_roc(y_test, y_test_pred, 'ROC Curve (Test Data)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"/afs/cern.ch/user/s/sraj/sraj/www/CUA/HH-bbgg/plots_v1/NMSSM_signal/ML_plots/highX_highY_ROC(after_variable_removal).png\")\n",
    "plt.savefig(\"/afs/cern.ch/user/s/sraj/sraj/www/CUA/HH-bbgg/plots_v1/NMSSM_signal/ML_plots/highX_highY_ROC(after_variable_removal).pdf\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(14, 5))\n",
    "\n",
    "# Plot Training and Testing Loss\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(range(1, epochs + 1), train_losses, label='Training Loss')\n",
    "plt.plot(range(1, epochs + 1), test_losses, label='Testing Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Loss Curve')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "\n",
    "# Plot Training and Testing Accuracy\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(range(1, epochs + 1), train_accuracies, label='Training Accuracy')\n",
    "plt.plot(range(1, epochs + 1), test_accuracies, label='Testing Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Accuracy Curve')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to get predictions from the PyTorch model\n",
    "def get_predictions(loader, model):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels, _ in loader:\n",
    "            outputs = model(inputs)\n",
    "            outputs = outputs.squeeze()\n",
    "            all_preds.extend(outputs.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "    return np.array(all_preds), np.array(all_labels)\n",
    "# Get predictions for training and test data\n",
    "train_preds, train_true = get_predictions(train_loader, model)\n",
    "test_preds, test_true = get_predictions(test_loader, model)\n",
    "\n",
    "# Convert weights tensors to NumPy arrays\n",
    "X_train_weights_np = X_train_weights_tensor.numpy()\n",
    "X_test_weights_np = X_test_weights_tensor.numpy()\n",
    "\n",
    "# Define bins\n",
    "bins = np.linspace(0, 1, 31)  \n",
    "\n",
    "# Calculate histograms and bins for training data with weights\n",
    "train_hist_s, _ = np.histogram(train_preds[train_true == 1], bins=bins, density=True, weights=X_train_weights_np[train_true == 1])\n",
    "train_hist_b, _ = np.histogram(train_preds[train_true == 0], bins=bins, density=True, weights=X_train_weights_np[train_true == 0])\n",
    "\n",
    "# Calculate bin centers\n",
    "bin_centers = (bins[:-1] + bins[1:]) / 2\n",
    "\n",
    "# Plot histograms for training data\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.hist(train_preds[train_true == 1], bins=bins, color='blue', alpha=0.5, label='Signal (Train)', density=True, weights=X_train_weights_np[train_true == 1])\n",
    "plt.hist(train_preds[train_true == 0], bins=bins, color='red', alpha=0.5, label='Background (Train)', density=True, weights=X_train_weights_np[train_true == 0])\n",
    "\n",
    "# Calculate histograms for test data\n",
    "test_hist_s, _ = np.histogram(test_preds[test_true == 1], bins=bins, density=True, weights=X_test_weights_np[test_true == 1])\n",
    "test_hist_b, _ = np.histogram(test_preds[test_true == 0], bins=bins, density=True, weights=X_test_weights_np[test_true == 0])\n",
    "\n",
    "# Plot scatter points for test data\n",
    "plt.scatter(bin_centers, test_hist_s, color='blue', alpha=0.7, label='Signal (Test)', marker='o', s=30, edgecolor='k')\n",
    "plt.scatter(bin_centers, test_hist_b, color='red', alpha=0.7, label='Background (Test)', marker='o', s=30, edgecolor='k')\n",
    "\n",
    "\n",
    "# Add background colors\n",
    "plt.axvspan(0, 0.5, color='red', alpha=0.1)\n",
    "plt.axvspan(0.5, 1, color='blue', alpha=0.1)\n",
    "\n",
    "plt.axvline(0.5, color='k', linestyle='--')\n",
    "plt.xlabel('Classifier output')\n",
    "plt.ylabel('Normalized Yields')\n",
    "plt.xlim(0,1)\n",
    "plt.legend(loc='upper center')\n",
    "plt.title('Classifier Output with PyTorch')\n",
    "\n",
    "# Save and display the plotpurple\n",
    "plt.savefig(\"/afs/cern.ch/user/s/sraj/sraj/www/CUA/HH-bbgg/plots_v1/NMSSM_signal/ML_plots/highX_highY_classifier_output_plot(after_variable_removal).png\")\n",
    "plt.savefig(\"/afs/cern.ch/user/s/sraj/sraj/www/CUA/HH-bbgg/plots_v1/NMSSM_signal/ML_plots/highX_highY_classifier_output_plot(after_variable_removal).pdf\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation plot "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot correlation matrix before training\n",
    "X_train_df = pd.DataFrame(X_train_scaled, columns=features)\n",
    "corr_matrix_before = X_train_df.corr()\n",
    "\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(corr_matrix_before, annot=True, cmap='coolwarm', fmt='.2f', vmin=-1, vmax=1,\n",
    "            square=True, cbar_kws={\"shrink\": .8}, linewidths=.5)\n",
    "plt.title('Feature Correlation Matrix Before Training')\n",
    "plt.savefig(\"/afs/cern.ch/user/s/sraj/sraj/www/CUA/HH-bbgg/plots_v1/NMSSM_signal/ML_plots/correlation(after_variable_removal)_before_training.png\")\n",
    "plt.savefig(\"/afs/cern.ch/user/s/sraj/sraj/www/CUA/HH-bbgg/plots_v1/NMSSM_signal/ML_plots/correlation(after_variable_removal)_before_training.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot correlation matrix after training\n",
    "X_train_after_df = pd.DataFrame(X_train_scaled, columns=features)\n",
    "corr_matrix_after = X_train_after_df.corr()\n",
    "\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(corr_matrix_after, annot=True, cmap='coolwarm', fmt='.2f', vmin=-1, vmax=1,\n",
    "            square=True, cbar_kws={\"shrink\": .8}, linewidths=.5)\n",
    "plt.title('Feature Correlation Matrix After Training')\n",
    "plt.savefig(\"/afs/cern.ch/user/s/sraj/sraj/www/CUA/HH-bbgg/plots_v1/NMSSM_signal/ML_plots/lowX_lowY_correlation_after_training.png\")\n",
    "plt.savefig(\"/afs/cern.ch/user/s/sraj/sraj/www/CUA/HH-bbgg/plots_v1/NMSSM_signal/ML_plots/lowX_lowY_correlation_after_training.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variable ranking "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "def permutation_importance(model, X_val, y_val, baseline_acc, n_repeats=10):\n",
    "    \"\"\"\n",
    "    Calculate permutation importance for a given model on validation data.\n",
    "    \n",
    "    Parameters:\n",
    "    - model: Trained PyTorch model\n",
    "    - X_val: Validation features (numpy array)\n",
    "    - y_val: Validation labels (numpy array)\n",
    "    - baseline_acc: Baseline accuracy of the model on unperturbed data\n",
    "    - n_repeats: Number of shuffles for each feature\n",
    "\n",
    "    Returns:\n",
    "    - importances: A dictionary with features as keys and importance scores\n",
    "    \"\"\"\n",
    "    importances = {col: [] for col in range(X_val.shape[1])}  # Create dictionary to store importances\n",
    "    X_val_copy = X_val.copy()  # Create a copy of the validation data\n",
    "\n",
    "    for col in range(X_val.shape[1]):  # Loop over each feature\n",
    "        permuted_acc = []\n",
    "        for _ in range(n_repeats):\n",
    "            np.random.shuffle(X_val_copy[:, col])  # Randomly shuffle one feature column\n",
    "            with torch.no_grad():\n",
    "                outputs = model(torch.tensor(X_val_copy, dtype=torch.float32)).squeeze()\n",
    "                permuted_acc.append(accuracy_score(y_val, (outputs > 0.5).numpy()))\n",
    "        # Calculate importance as the difference between baseline and permuted accuracy\n",
    "        importances[col] = baseline_acc - np.mean(permuted_acc)\n",
    "        X_val_copy[:, col] = X_val[:, col]  # Reset column to original values\n",
    "\n",
    "    return importances\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute baseline accuracy on validation data\n",
    "with torch.no_grad():\n",
    "    baseline_outputs = model(X_test_tensor).squeeze()\n",
    "    baseline_accuracy = accuracy_score(y_test, (baseline_outputs > 0.5).numpy())\n",
    "\n",
    "# Calculate permutation importance\n",
    "feature_importances = permutation_importance(model, X_test_scaled, y_test.values, baseline_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract feature names and their corresponding importances\n",
    "feature_names = features  # List of feature names from your dataset\n",
    "importance_values = [feature_importances[i] for i in range(len(feature_names))]\n",
    "\n",
    "# Sort features by importance\n",
    "sorted_indices = np.argsort(importance_values)[::-1]\n",
    "sorted_importances = np.array(importance_values)[sorted_indices]\n",
    "sorted_features = np.array(feature_names)[sorted_indices]\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.barh(sorted_features, sorted_importances, color='skyblue')\n",
    "plt.xlabel('Importance Score')\n",
    "plt.title('Feature Importance Ranking')\n",
    "plt.gca().invert_yaxis()  # Highest importance at the top\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## After correlation variable removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "def permutation_importance(model, X_val, y_val, baseline_acc, n_repeats=10):\n",
    "    \"\"\"\n",
    "    Calculate permutation importance for a given model on validation data.\n",
    "    \n",
    "    Parameters:\n",
    "    - model: Trained PyTorch model\n",
    "    - X_val: Validation features (numpy array)\n",
    "    - y_val: Validation labels (numpy array)\n",
    "    - baseline_acc: Baseline accuracy of the model on unperturbed data\n",
    "    - n_repeats: Number of shuffles for each feature\n",
    "\n",
    "    Returns:\n",
    "    - importances: A dictionary with features as keys and importance scores\n",
    "    \"\"\"\n",
    "    importances = {col: [] for col in range(X_val.shape[1])}  # Create dictionary to store importances\n",
    "    X_val_copy = X_val.copy()  # Create a copy of the validation data\n",
    "\n",
    "    for col in range(X_val.shape[1]):  # Loop over each feature\n",
    "        permuted_acc = []\n",
    "        for _ in range(n_repeats):\n",
    "            np.random.shuffle(X_val_copy[:, col])  # Randomly shuffle one feature column\n",
    "            with torch.no_grad():\n",
    "                outputs = model(torch.tensor(X_val_copy, dtype=torch.float32)).squeeze()\n",
    "                permuted_acc.append(accuracy_score(y_val, (outputs > 0.5).numpy()))\n",
    "        # Calculate importance as the difference between baseline and permuted accuracy\n",
    "        importances[col] = baseline_acc - np.mean(permuted_acc)\n",
    "        X_val_copy[:, col] = X_val[:, col]  # Reset column to original values\n",
    "\n",
    "    return importances\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute baseline accuracy on validation data\n",
    "with torch.no_grad():\n",
    "    baseline_outputs = model(X_test_tensor).squeeze()\n",
    "    baseline_accuracy = accuracy_score(y_test, (baseline_outputs > 0.5).numpy())\n",
    "\n",
    "# Calculate permutation importance\n",
    "feature_importances = permutation_importance(model, X_test_scaled, y_test.values, baseline_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract feature names and their corresponding importances\n",
    "feature_names = features  # List of feature names from your dataset\n",
    "importance_values = [feature_importances[i] for i in range(len(feature_names))]\n",
    "\n",
    "# Sort features by importance\n",
    "sorted_indices = np.argsort(importance_values)[::-1]\n",
    "sorted_importances = np.array(importance_values)[sorted_indices]\n",
    "sorted_features = np.array(feature_names)[sorted_indices]\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.barh(sorted_features, sorted_importances, color='skyblue')\n",
    "plt.xlabel('Importance Score')\n",
    "plt.title('Feature Importance Ranking')\n",
    "plt.gca().invert_yaxis()  # Highest importance at the top\n",
    "plt.savefig(\"/afs/cern.ch/user/s/sraj/sraj/www/CUA/HH-bbgg/plots_v1/NMSSM_signal/Variable_rankking_after_correlating_variable_removal.png\")\n",
    "plt.savefig(\"/afs/cern.ch/user/s/sraj/sraj/www/CUA/HH-bbgg/plots_v1/NMSSM_signal/Variable_rankking_after_correlating_variable_removal.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
